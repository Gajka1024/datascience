{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#wczytanie zbioru danych\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podzielenie zbiorów danych na przestrzeń cech i przestrzeń etykiet\n",
    "data = df.values\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zastosowanie prostego, losowego podziału zbiorów na dwie części\n",
    "splits = model_selection.train_test_split(X, y, test_size=.333, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przypisanie do podzbiorów odpowiednich zmiennych\n",
    "X_train, X_test, y_train, y_test = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (50, 4) (100,) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "##Proces uczenia i predykcja\n",
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "#nauczanie na zbiorach treningowych\n",
    "clf.fit(X_train, y_train)\n",
    "#określenie jakości/dokładności klasyfikatora\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.6 0.4]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.8 0.2]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Uzyskanie wektora wsparć\n",
    "support_vector = clf.predict_proba(X_test)\n",
    "print(support_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Wyznaczenie predykcji\n",
    "prediction = np.argmax(support_vector,axis = 1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "#\"przetłumaczenie\" indeksów na odpowiadajace im oznaczenia\n",
    "prediction = clf.classes_[prediction]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Wyznaczenie macierzy pomyłek, informującej o wzorcach poprawnie przypisanych do swoich klas\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, prediction)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# wyznaczenie stosunek sumy wartości znajdujących się na przekątnej macierzy pomyłek \n",
    "# do sumy wszystkich wartości macierzy\n",
    "accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9333333333333333, 1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#zastosowanie walidacji krrzyżowej\n",
    "#deklaracja zmiennej (10 podziałów)\n",
    "k = 10\n",
    "#inicjalizacja zmiennej\n",
    "cv = model_selection.StratifiedKFold(n_splits=k)\n",
    "\n",
    "accuracies = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    probas = clf.predict_proba(X_test)\n",
    "    prediction = np.argmax(probas,axis = 1)\n",
    "    prediction = clf.classes_[prediction]\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność 0.967 (+- 0.04)\n"
     ]
    }
   ],
   "source": [
    "#Wypisanie wektora dokładnosci poprzez uśrednioną dokładność oraz odchylenie standardowe\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(\"Średnia dokładność %.3f (+- %.2f)\" % (mean_accuracy, std_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Porównywanie klasyfikatorów\n",
    "\n",
    "from sklearn import neighbors\n",
    "clfs = [\n",
    "    neighbors.KNeighborsClassifier(n_neighbors = 1),\n",
    "    neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(url, header=None)\n",
    "data = df.values\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.        ]\n",
      " [0.93333333 0.93333333]\n",
      " [1.         1.        ]\n",
      " [0.93333333 1.        ]\n",
      " [0.86666667 0.86666667]\n",
      " [1.         0.93333333]\n",
      " [0.86666667 0.93333333]\n",
      " [1.         1.        ]\n",
      " [1.         1.        ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "cv = model_selection.StratifiedKFold(n_splits=k)\n",
    "\n",
    "results = []\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    result = []\n",
    "    for clf in clfs:\n",
    "        clf.fit(X_train, y_train)\n",
    "        probas = clf.predict_proba(X_test)\n",
    "        prediction = np.argmax(probas,axis = 1)\n",
    "        prediction = clf.classes_[prediction]\n",
    "        accuracy = metrics.accuracy_score(y_test, prediction),\n",
    "        result.append(accuracy[0])\n",
    "    results.append(result)\n",
    "results = np.array(results)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96       0.96666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Y700\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\stats\\morestats.py:2863: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "#Wykonanie testów odpowiednimy funkcjami\n",
    "test_t = stats.ttest_ind(results[:,0],results[:,1])\n",
    "test_w = stats.wilcoxon(results[:,0],results[:,1])\n",
    "#Wyświetlenie średniej dokładności uzyskanej przez oba klasyfikatory.\n",
    "print(np.mean(results,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.2873478855663521, pvalue=0.7771278487505224)\n",
      "WilcoxonResult(statistic=2.0, pvalue=0.5637028616507731)\n"
     ]
    }
   ],
   "source": [
    "print(test_t)\n",
    "print(test_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
